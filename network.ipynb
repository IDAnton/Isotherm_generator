{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def softmax(t):\n",
    "    res = np.exp(t)\n",
    "    return res / np.sum(res)\n",
    "\n",
    "def relu(t):\n",
    "    return np.maximum(t, 0)\n",
    "\n",
    "def relu_deriv(t):\n",
    "    return (t>=0).astype(float)\n",
    "\n",
    "def to_one_hot_encoding(y, dim = 10):\n",
    "    res = np.zeros([1, dim])\n",
    "    res[0][y] = 1\n",
    "    return res\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_dim, h1_dim, h2_dim, out_dim, learn_rate = 0.005):\n",
    "        self.input_dim = input_dim\n",
    "        self.h1_dim = h1_dim\n",
    "        self.h2_dim = h2_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.learn_rate = learn_rate\n",
    "\n",
    "        self.t1 = np.zeros([1, self.h1_dim])\n",
    "        self.h1 = np.zeros([1, self.h1_dim])\n",
    "        self.t2 = np.zeros([1, self.h2_dim])\n",
    "        self.h2 = np.zeros([1, self.h2_dim])\n",
    "        self.t3 = np.zeros([1, self.out_dim])\n",
    "        self.out = np.zeros([1, self.out_dim])\n",
    "\n",
    "        self.w1 = np.random.rand(self.input_dim, self.h1_dim) - 0.5\n",
    "        self.b1 = np.random.rand(1, self.h1_dim) - 0.5\n",
    "        self.w2 = np.random.rand(self.h1_dim, self.h2_dim) - 0.5\n",
    "        self.b2 = np.random.rand(1, self.h2_dim) - 0.5\n",
    "        self.w3 = np.random.rand(self.h2_dim, self.out_dim) - 0.5\n",
    "        self.b3 = np.random.rand(1, self.out_dim) - 0.5\n",
    "        self.drop_gradients()\n",
    "\n",
    "\n",
    "    def drop_gradients(self):\n",
    "        self.dE_dw1 = np.zeros((self.input_dim, self.h1_dim))\n",
    "        self.dE_db1 = np.zeros((1, self.h1_dim))\n",
    "        self.dE_dw2 = np.zeros((self.h1_dim, self.h2_dim))\n",
    "        self.dE_db2 = np.zeros((1, self.h2_dim))\n",
    "        self.dE_dw3 = np.zeros((self.h2_dim, self.out_dim))\n",
    "        self.dE_db3 = np.zeros((1, self.out_dim))\n",
    "\n",
    "\n",
    "    def run(self, data, activation_function):\n",
    "        self.t1 = data @ self.w1 + self.b1\n",
    "        self.h1 = activation_function(self.t1)\n",
    "        self.t2 = self.h1 @ self.w2 + self.b2\n",
    "        self.h2 = activation_function(self.t2)\n",
    "        self.t3 = self.h2 @ self.w3 + self.b3\n",
    "        self.out = self.t3\n",
    "        return self.out\n",
    "\n",
    "\n",
    "    def calculate_gradient(self, data, right_out, activation_deriv):\n",
    "        dE_dt3 = self.out - right_out\n",
    "        self.dE_dw3 += self.h2.T @ dE_dt3\n",
    "        self.dE_db3 = dE_dt3\n",
    "\n",
    "        dE_dh2 = dE_dt3 @ self.w3.T\n",
    "        dE_dt2 = dE_dh2 * activation_deriv(self.t2)\n",
    "        self.dE_dw2 += self.h1.T @ dE_dt2\n",
    "        self.dE_db2 += dE_dt2\n",
    "\n",
    "        dE_dh3 = dE_dt2 @ self.w2.T\n",
    "        dE_dt3 = dE_dh3 * activation_deriv(self.t1)\n",
    "        self.dE_dw1 += data.T @ dE_dt3\n",
    "        self.dE_db1 += dE_dt3\n",
    "\n",
    "\n",
    "    def apply_gradient(self, batch_size=1):\n",
    "        self.w1 -= self.learn_rate * self.dE_dw1 / batch_size\n",
    "        self.w2 -= self.learn_rate * self.dE_dw2 / batch_size\n",
    "        self.b1 -= self.learn_rate * self.dE_db1 / batch_size\n",
    "        self.b2 -= self.learn_rate * self.dE_db2 / batch_size\n",
    "        self.b3 -= self.learn_rate * self.dE_db3 / batch_size\n",
    "\n",
    "        self.drop_gradients()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test):\n",
    "    for epoch in range (1, 3):\n",
    "        loss = 0\n",
    "        for i in range(0, len(X_train)):\n",
    "            prediction = model.run(data=X_train[i].flatten(), activation_function=relu)\n",
    "            loss += np.sum((y_train[i] - prediction))/ np.sum(y_train[i])\n",
    "            model.calculate_gradient(data=(X_train[i]).reshape(1,100*100), right_out=y_train[i], activation_deriv=relu_deriv)\n",
    "            if i % 20 == 0:\n",
    "                model.apply_gradient()\n",
    "\n",
    "        test_loss = 0\n",
    "        # for i in range(0, 10000):\n",
    "        #     prediction = np.argmax(model.run(data=X_test[i], activation_function=relu))\n",
    "        #     test_loss += (y_test[i] - prediction) ** 2\n",
    "        print(f\"Epoch â„–{epoch} finished with accuracy {round(loss/len(X_train) * 100, 2)}% Test dataset accuracy {round(test_loss/len(X_train) * 100, 2)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = np.load(\"data/test/test_x.npy\")\n",
    "y_train = np.load(\"data/test/test_y.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model = Perceptron(input_dim=100*100, h1_dim=100, h2_dim=20, out_dim=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_model(model, X_train, y_train, X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 9009\n",
    "right_answer = model.run(data=X_train[i].flatten(), activation_function=relu)\n",
    "print(right_answer, y_train[i])\n",
    "fig = plt.figure\n",
    "plt.imshow(X_train[i], origin='lower', cmap='gray')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}