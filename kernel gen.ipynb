{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "def softmax(t):\n",
    "    res = np.exp(t)\n",
    "    return res / np.sum(res)\n",
    "\n",
    "def relu(t):\n",
    "    return np.maximum(t, 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "def relu_deriv(t):\n",
    "    return (t>=0).astype(float)\n",
    "\n",
    "def to_one_hot_encoding(y, dim = 10):\n",
    "    res = np.zeros([1, dim])\n",
    "    res[0][y] = 1\n",
    "    return res\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_dim, h1_dim, out_dim, learn_rate = 0.05):\n",
    "        self.input_dim = input_dim\n",
    "        self.h1_dim = h1_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.learn_rate = learn_rate\n",
    "\n",
    "        self.t1 = np.zeros([1, self.h1_dim])\n",
    "        self.h1 = np.zeros([1, self.h1_dim])\n",
    "        self.t2 = np.zeros([1, self.out_dim])\n",
    "        self.out = np.zeros([1, self.out_dim])\n",
    "\n",
    "        self.w1 = (np.random.rand(self.input_dim, self.h1_dim) - 0.5)*0.1\n",
    "        self.b1 = (np.random.rand(1, self.h1_dim) - 0.5)*0.1\n",
    "        self.w2 = (np.random.rand(self.h1_dim, self.out_dim) - 0.5)*0.1\n",
    "        self.b2 = (np.random.rand(1, self.out_dim) - 0.5)*0.1\n",
    "        self.drop_gradients()\n",
    "\n",
    "\n",
    "    def drop_gradients(self):\n",
    "        self.dE_dw1 = np.zeros((self.input_dim, self.h1_dim))\n",
    "        self.dE_db1 = np.zeros((1, self.h1_dim))\n",
    "        self.dE_dw2 = np.zeros((self.h1_dim, self.out_dim))\n",
    "        self.dE_db2 = np.zeros((1, self.out_dim))\n",
    "\n",
    "\n",
    "    def run(self, data, activation_function):\n",
    "        self.t1 = data @ self.w1 + self.b1\n",
    "        self.h1 = activation_function(self.t1)\n",
    "        self.t2 = self.h1 @ self.w2 + self.b2\n",
    "        self.out = self.t2\n",
    "        return self.out\n",
    "\n",
    "\n",
    "    def calculate_gradient(self, data, right_out, activation_deriv):\n",
    "        dE_dt2 = 2*(self.out - right_out)\n",
    "        self.dE_dw2 += self.h1.T @ dE_dt2\n",
    "        self.dE_db2 += dE_dt2\n",
    "\n",
    "        dE_dh1 = dE_dt2 @ self.w2.T\n",
    "        dE_dt1 = dE_dh1 * activation_deriv(self.t1)\n",
    "        self.dE_dw1 += data @ dE_dt1\n",
    "        self.dE_db1 += dE_dt1\n",
    "\n",
    "\n",
    "    def apply_gradient(self, batch_size=1):\n",
    "        self.w1 -= self.learn_rate * self.dE_dw1 / batch_size\n",
    "        self.w2 -= self.learn_rate * self.dE_dw2 / batch_size\n",
    "        self.b1 -= self.learn_rate * self.dE_db1 / batch_size\n",
    "        self.b2 -= self.learn_rate * self.dE_db2 / batch_size\n",
    "\n",
    "        self.drop_gradients()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test):\n",
    "    for epoch in range (1, 2000):\n",
    "        loss = 0\n",
    "        inner_counter = 1\n",
    "        for i in np.random.permutation(len(X_train)):\n",
    "            prediction = model.run(data=X_train[i].flatten(), activation_function=relu)\n",
    "            loss += np.abs(y_train[i] - prediction[0][0])\n",
    "            model.calculate_gradient(data=X_train[i].reshape(2, 1), right_out=y_train[i].flatten(), activation_deriv=relu)\n",
    "            if inner_counter % 50 == 0:\n",
    "                model.apply_gradient(batch_size=50)\n",
    "            inner_counter += 1\n",
    "\n",
    "        test_loss = 0\n",
    "        # for i in range(0, 10000):\n",
    "        #     prediction = np.argmax(model.run(data=X_test[i], activation_function=relu))\n",
    "        #     test_loss += (y_test[i] - prediction) ** 2\n",
    "        print(f\"Epoch №{epoch} finished with accuracy {round(loss/len(X_train), 3)}% Test dataset accuracy {round(test_loss/len(X_train) * 100, 2)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "P_START = 21\n",
    "dataframe_sorb = pd.read_excel('Silica-loc-isoth1.xlsx', header=None, sheet_name=\"Adsorption\")\n",
    "AX_train = []\n",
    "PX_train = []\n",
    "pore_N = dataframe_sorb.shape[1]\n",
    "AX_train = np.array(dataframe_sorb.iloc[0][1:])\n",
    "PX_train = np.array(dataframe_sorb[0][P_START:])\n",
    "ax_scale = np.max(AX_train)\n",
    "px_scale = np.max(PX_train)\n",
    "AX_train = AX_train / ax_scale\n",
    "PX_train = PX_train / px_scale\n",
    "\n",
    "X_train = np.empty(shape = (len(AX_train) * len(PX_train), 2))\n",
    "Y_train = np.empty(shape =len(AX_train) * len(PX_train))\n",
    "k = 0\n",
    "for i in range(0, len(AX_train)):\n",
    "    for j in range(0, len(PX_train)):\n",
    "        X_train[k] = np.array([AX_train[i], PX_train[j]])\n",
    "        Y_train[k] = dataframe_sorb[i+1][j+P_START]\n",
    "        k+=1\n",
    "y_scale = np.max(Y_train)\n",
    "Y_train = Y_train / y_scale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "model = Perceptron(input_dim=2, h1_dim=10, out_dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch №1 finished with accuracy 0.191% Test dataset accuracy 0.0\n",
      "Epoch №2 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №3 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №4 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №5 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №6 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №7 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №8 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №9 finished with accuracy 0.067% Test dataset accuracy 0.0\n",
      "Epoch №10 finished with accuracy 0.067% Test dataset accuracy 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[281], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mlearn_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.1\u001B[39m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[269], line 6\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, X_train, y_train, X_test, y_test)\u001B[0m\n\u001B[0;32m      4\u001B[0m inner_counter \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mpermutation(\u001B[38;5;28mlen\u001B[39m(X_train)):\n\u001B[1;32m----> 6\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mrun(data\u001B[38;5;241m=\u001B[39m\u001B[43mX_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, activation_function\u001B[38;5;241m=\u001B[39mrelu)\n\u001B[0;32m      7\u001B[0m     loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mabs(y_train[i] \u001B[38;5;241m-\u001B[39m prediction[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      8\u001B[0m     model\u001B[38;5;241m.\u001B[39mcalculate_gradient(data\u001B[38;5;241m=\u001B[39mX_train[i]\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m), right_out\u001B[38;5;241m=\u001B[39my_train[i]\u001B[38;5;241m.\u001B[39mflatten(), activation_deriv\u001B[38;5;241m=\u001B[39mrelu)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.learn_rate = 0.1\n",
    "train_model(model, X_train, Y_train, X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03939321]] 0.559004485607147\n"
     ]
    }
   ],
   "source": [
    "i = -1\n",
    "a = []\n",
    "right_answer = model.run(data=X_train[i].flatten(), activation_function=relu)\n",
    "#dataframe_sorb = pd.read_excel('Silica-loc-isoth1.xlsx', header=None, sheet_name=\"Adsorption\")\n",
    "# data_sorb = dataframe_sorb.to_numpy()\n",
    "# pressures_d = data_sorb[:, 0][21:]\n",
    "# plt.plot(pressures_d, y_train[i] * y_scale, marker=\".\")\n",
    "# plt.plot(pressures_d, right_answer.reshape(458, 1) * y_scale , marker=\".\")\n",
    "print(right_answer*y_scale, Y_train[i]*y_scale)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}